[{"lang":"en","lvl2":"Pre-requisites\nDevelopment stack\nDeployment capabilities/integration\nTesting\nHTTP Server\nHTTP Client\nPersistence\nSpring Boot\nQuarkus\nMicroprofile\nGo further with GraalVM","text":"Ensure to use java >= 11\n(Optional) Ensure to use a dependency manager such as Apache Maven/Gradle/SBT or Apache Ivy.\nusing SDKMan can greatly simplify the installation.\nThe goal of µShip is to promote and enable JSON-RPC development at scale. For that it provides a CDI-Servlet integration module known as jsonrpc-core module.\nHowever, µShip also provides all the underlying stack to make it functional such as:\nAn embedded Servlet container (Apache Tomcat),\nJSON-P/JSON-B integration modules,\nJSON-RPC API/implementation and documentation utilities.\nas of today, µShip does not go further - as providing a configuration/openmetrics/opentracing/JWT integration since these ones can easily be added using CDI libraries. It will probably be tackled in a few versions but was not a pre-requisite of the project.\nRead more.\nBy using CDI standalone (a.k.a. CDI SE) and an embedded Apache Tomcat, µShip enables to deliver application as:\nAssemblies (just use java -cp folder-with-dependencies-and-application-jars/*.jar com.app.YourMain - or reuse µShip main),\nDocker images using jib-maven-plugin.\nby using a flat classpath, µShip is perfectly compatible with java CDS which boosts a lot the startup in general, don’t hesitate to set it up if you care to start in less than a second.\nOnce again, by using a plain CDI base, testing is made easy and compatible with Apache OpenWebBeans tooling.\nUShip extends the JVM HttpClient to provide a few more features and callbacks. It also provides a Kubernetes client module which auto-setup a HttpClient from a POD.\nUShip provides a convenient JDBC light mapper.\nIf you want a Spring Boot JSON-RPC integration, you can reuse our jsonrpc-spring module.\nIf you want a Quarkus JSON-RPC integration, you can reuse our jsonrpc-quarkus module.\nIf you want a Microprofile JSON-RPC integration, you can reuse our jsonrpc-core module with some minimal setup.\nYou can also make your JSON-RPC (or web) server \"native\" thanks GraalVM. See the related documentation to learn more about it.","title":"Getting Started","url":"//yupiik.github.io/uship/getting-started.html"},{"lang":"en","text":"UShip stack is GraalVM native-image compatible, it means you can convert your application classpath to a native binary to optimize the resources consumption and performances of your application.\nYou can do it with a plain native-image command or use Geronimo Arthur to ease it.\nit requires Arthur 1.0.14 or more recent.\nHere is the overall configuration for a standard application (using Yupiik Logging, Yupiik Batch simple configuration, Yupiik UShip JSON-RPC server and persistence layer with PostgreSQL driver), adapt it to your stack:\nthis configuration will work for your models if they have at least one explicit @JsonbProperty otherwise you will need to register them explicitly in <reflections> section or use @RegisterClass on the model (from arthur-api package, it can be in provided scope).\nif you want openrpc method to work properly, ensure to define the following reflections:\nFinally, if you use io.yupiik.uship.persistence.impl.datasource.tomcat.TomcatDataSource you can need to define the following proxy:","title":"GraalVM","url":"//yupiik.github.io/uship/graalvm.html"},{"lang":"en","lvl2":"Request Listeners\nKubernetes client\nJSON-RPC client","lvl3":"Default Listeners\nSample usage\n(Open) Tracing\nBulk handling","text":"UShip HTTP Client is based on java.net.http.HttpClient. It is configured with ExtendedHttpClientConfiguration which enables to:\noptionally provide a configured HttpClient instance - otherwise the default JVM one is used,\noptionally provide a set of `RequestListener`s which listen for requests.\nRequest listener is a callback triggered before and after each request. It enables to store data before the requests in the caller context and execute some callback once the request is finished. To pass data between both steps (since the request can be asynchronous or not) it uses a State which can hold any data the listener needs.\nif you write custom listeners (to add OpenTracing capabilities for example), you can make them implement AutoCloseable and when closing the HTTP client the method will be called automatically.\nThis listener is pretty straight forward, if the request does not have a timeout, it sets it to the default one configured in the listener. It enables to enforce a global timeout to all requests.\nThis listener enforce a custom user-agent value. It defaults to chrome one.\nThis listener enables to force all exchanges to be logged.\nThis listener enables to capture a HAR dump of all exchanges which went through the client. It can be very useful to generate some test data you replay with a HAR server in a test or a demo environment.\nthis is not in the same module, you must add tracing module to get this feature.\ntracing module provides a Tomcat valve you can set up on your web container to add tracing capabilities to your Tomcat:\nThe configuration enables to customize the span tags and headers to enrich the request with,\nThe accumulator is what will send/log/… the spans once aggregated, ensure to configure it as needed,\nThe IdGenerator provides the span/trace identifiers, it must be compatible with your collector (hex for zipkin for example),\nActually a Supplier<Span>, the span evaluator enables to get parent span, here from the request in a webserver-tomcat using Tracingvalve but any evaluation will work,\nThe clock enables to timestamp the span and compute its duration,\nFinally, add the listener to your http client configuration and create your client.\nthe accumulator should generally be closed if you reuse AccumulatingSpanCollector. You can combine it with ZipkinFlusher to flush to a zipkin collector v2.\nkubernetes-client modules providers a HTTP Client already configured for Kubernetes in cluster connection (from a POD). This will typically be used from an operator or cloud native application to call Kubernetes API using a plain and very light HTTP Client from the JVM.\nindeed you can combine it with the enhanced HTTP Client configuring it in the KubernetesClientConfiguration. However, it is recommended to do it using setClientWrapper on the configuration and pass the automatically created client to ExtendedHttpClientConfiguration.setDelegate to avoid to have to handle the SSLContext yourself.\nUsage:\nas you can see, there is no need to pass the token to the request, it is done under the hood by the KubernetesClient. The other important note is that https://kubernetes.api is automatically replaced by the conf.getMaster() value. This enables your code to stay more straight forward in general but if you pass them, the client will handle it properly too.\nAs a JSON-RPC server companion UShip also provides a JSON-RPC client.\nThe minimum configuration is to provide the JSON-RPC endpoint:\nBut more is customizable in JsonRpcClientConfiguration and a common initialization would look like:\nThen you can simply use it in your application:\nBulk is handled relying on the JSON-RPC protocol accessible from the client - or directly if you prefer:","title":"HTTP Client","url":"//yupiik.github.io/uship/http-client.html"},{"lang":"en","lvl2":"Modes\nStandalone mode\nCDI Mode\n(Open) Tracing","text":"µship comes with two Tomcat modules:\nwebserver-tomcat which is a thin Apache Tomcat wrapper creating - by default - a ROOT context,\nwebserver-cdi which integrated webserver-tomcat with CDI.\nThe standalone mode (webserver-tomcat) is mainly about creating a TomcatWebServerConfiguration and instantiating a TomcatWebServer:\nCreate a configuration instance,\nYou can bind any servlet, filter etc using initializers,\nCreate a server (create call is what starts the server) and don’t forget to close is when no more needed (done with try-with-resource syntax there),\nThe port can be random using 0 in the original configuration, it will be updated after the startup of the server in this case.\ndefault Tomcat scanning (@WebServlet etc) is not enabled - you will see that with CDI it is rarely needed - but you can enable it adding a context customizer registering ContextConfig:\n+\nCDI mode is almost the same as standalone mode except:\nYou can (optional) produce TomcatWebServerConfiguration in CDI context:\nIt can be a standard subclass of the POJO TomcatWebServerConfiguration or like here a producer, in all cases it is recommended to use @ApplicationScoped even if not required to ensure the instance is shared between injection if you reuse it soewhere else (like in tests or in a servlet),\nCreate the configuration (same as standalone case), here te trick is generally to reuse the native configuration mecanism of the application (microprofile config for example),\nAdd a context customizer to customize the docbase, context name etc…\nYou can (optional) create ServletContextInitializer, ContextCustomizer and TomcatCustomizer beans (with @Default qualifier) which will automatically be injected in the TomcatWebServerConfiguration.\nno need of a META-INF/services/jakarta.servlet.ServletContainerInitializer file in this case, CDI is the registry used.\ntracing module provides a Tomcat valve you can set up on your web container to add tracing capabilities to your Tomcat:\nAdd the valve to the context pipeline, it is recommended to add it as early as possible (just after error report and access log valve in general),\nThe configuration enables to customize the span tags and headers to read for span propagation,\nThe accumulator is what will send/log/… the spans once aggregated, ensure to configure it as needed,\nThe IdGenerator provides the span/trace identifiers, it must be compatible with your collector (hex for zipkin for example),\nFinally the clock enables to timestamp the span and compute its duration.\nif you reuse AccumulatingSpanCollector, it is automatically closed with the valve \"stop\" phase. You can combine the accumulator with ZipkinFlusher onFlush implementation to flush to a zipkin collector v2.","title":"HTTP Server","url":"//yupiik.github.io/uship/http-server.html"},{"lang":"en","text":"","title":"Index","url":"//yupiik.github.io/uship/index.html"},{"lang":"en","lvl2":"Tip","text":"On this page we want to implement a first optimization on our JSON-RPC server.\nthis page will not go through the complete details of such optimization and only consider the pure case where all requests match but a real implement could group requests to still optimize the execution when sub requests are groupable (a plan should group requests and use the optimize case when possible and not only optimize all or nothing).\nfor a simpler implementation you can review io.yupiik.uship.jsonrpc.core.plan.SimpleExecutionPlanCompanion which enables to write checks more easily.\nThe use case is the following one:\nYou have a JSON-RPC method findById which takes two parameters id and logo (a boolean to request to include the logo url or not),\nYou have a java service method called findByIds which can load multiple entities at once (WHERE id in (…)).\nThe idea is to replace a bulk request of findById by an optimized execution using findByIds making the server execution optimized even if the client request is not optimal.\nHere is a sample implementation:\nIf not a bulk request we don’t optimize it, so we early quit,\nIf not an empty bulk request we can’t optimize it, so we early quit,\nIf the first bulk request is not an object we can’t evaluate it so use the default runtime to fail,\nIf the first bulk item does not have a method attribute we can’t evaluate it so use the default runtime to fail,\nIf previous conditions are met, try to optimize the execution,\nThis method enables us to route the optimizations specifically for a method (simpler to maintain),\nIf any request of the bulk is not a request then we can’t evaluate it so use the default runtime to fail,\nIf any request of the bulk is missing some parameter (keep in mind id and logo are required there) then we use the default runtime to fail,\nIf logo value is invalid use the default runtime to fail,\nIf multiple logo values, keep the default runtime execution (one by one instead of at once) - note that here we could group by logo value to do 2 optimizations or a more advanced query to optimize the runtime (out of scope of this post),\nExtract all identifiers for the bulk request,\nIf we have too many requests then fail - note that we could group there too but bulk request max size is 50 so we just aligned the value there (and luckily it is also aligned on the most common SQL limitations),\nTotally optional but we enrich the response to notify the caller we rewrote the execution (can be useful for debug purposes),\nWe do the optimized execution,\nwe map the result of the optimized execution to atomic Response (for each incoming request of the bulk request),\nSince our optimized execution was synchronous we wrap the responses in a CompletionStage - not needed if you already have one.\nWith java streams, you can write all these checks more fluently (note that some helper methods can ease that even more). All the trick relies on the fact to pass an enriched state between stream (of one element there) states:","title":"JSON-RPC execution plan example","url":"//yupiik.github.io/uship/jsonrpc-execution-plan.html"},{"lang":"en","lvl2":"For Microprofile servers with Servlet layer\nYour microprofile server does not have Servlet layer","text":"JSON-RPC server can easily be integrated with a Microprofile server.\nThe entry point is the module io.yupiik.uship:jsonrpc-core.\nthis is for jakarta based Microprofile servers, for javax one you need to redefine a few beans, you can check out jsonrpc-quarkus module for a sample.\nTo enable the server you can create a META-INF/services/jakarta.servlet.ServletContainerInitializer file in your resources registering io.yupiik.uship.jsonrpc.core.servlet.JsonRpcServletRegistration servlet. If you don’t want to bind /jsonrpc servlet, just register the servlet yourself on another binding instead of reusing default one.\nThe complete dependency set would look like:\nIf you use one of the very rare Microprofile server not having a servlet layer you can need to register the servlet different or a @POST JAX-RS endpoint delegating to JsonRpcServlet (but this is generally not needed):\nOnce done you can implement JSON-RPC methods using beans marked with @JsonRpc and methods with @JsonRpcMethod as in plain UShip server,","title":"Microprofile","url":"//yupiik.github.io/uship/microprofile.html"},{"lang":"en","lvl2":"Launcher\nCreate docker images","text":"To launch UShip, you just have to launch a CDI SE container. Using default implementation - Apache OpenWebBeans - it can be done using the default main(String…): org.apache.openwebbeans.se.CDILauncher. For the web server you can use --openwebbeans.main uShipTomcatAwait argument with CDILauncher to await Tomcat server and not quit immediately.\nOnce you collected all dependencies to be able to build the application classpath, simply set this class a your main and your application will start.\nWe highly recommend using JIB to create the docker images but you can also use a plain Dockerfile if desired. This documentation will use jib to provide an end to end example.\nHere is how to define Jib plugin to create a docker image:\nOnce configured you can build a local docker image using: mvn package jib:dockerBuild.\nusing mvn package jib:build, you can push the image to a remote registry without docker daemon. See jib documentation for more details.","title":"Packaging","url":"//yupiik.github.io/uship/packaging.html"},{"lang":"en","text":"JSON-RPC server is integrated with Quarkus.\nThe entry point is the module io.yupiik.uship:jsonrpc-quarkus. Once added you can:\nimplement JSON-RPC methods using beans marked with @JsonRpc and methods with @JsonRpcMethod,\nconfigure the base url of the OpenRPC value using jsonrpc.baseUrl (defaults to try to use localhost and the quarkus port) and jsonrpc.binding to configure the servlet binding in microprofile-config (application.properties), it defaults to /jsonrpc.\nHere is a sample:","title":"Quarkus","url":"//yupiik.github.io/uship/quarkus.html"},{"lang":"en","text":"JSON-RPC server is integrated with Spring Boot.\nThe entry point is the module io.yupiik.uship:jsonrpc-spring. Once added you can:\nmark your application with @EnableJsonRpc,\nimplement JSON-RPC methods using beans marked with @JsonRpc and methods with @JsonRpcMethod,\nconfigure the base url of the OpenRPC value using jsonrpc.baseUrl and binding url of the JSON-RPC endpoint with jsonrpc.binding in your application.properties (default uses the spring web server).\nHere is a sample:","title":"Spring Boot","url":"//yupiik.github.io/uship/spring-boot.html"},{"lang":"en","lvl2":"Testing an UShip application","text":"Testing an UShip application just requires to launch a CDI container. By default we rely on org.apache.openwebbeans:openwebbeans-junit5 to do so. It enables to start the container marking the test class with @Cdi:\nMark the test class to need a CDI SE container,\n@Cdi makes the test instance injections aware,\nThen simply write your tests as usual.\n@Cdi has some configuration options. One of the most interesting is to set reusable = true. It will enable to use the same container for all tests. Since, with this mode, all tests of the suite (configurable in surefire) must use the same flag, you can define a JUnit 5 stereotype:\nNow, instead of using @Cdi, you can use @MyAppSupport on test classes avoiding to miss a reusable = true configuration. It is also very useful to add extension to all tests at once, for example if you have some JPA enhancer to execute before the container starts or some entity spying to auto delete test data between test, you can add the extensions there:\nThe test will then not change:","title":"Testing","url":"//yupiik.github.io/uship/testing.html"},{"lang":"en","lvl2":"Setup your JSON-RPC service with µship stack\nCreate JSON-RPC endpoints\nDocument JSON-RPC endpoints\nOptimize your JSON-RPC execution\nPostman collection for JSON-RPC endpoint\nPersistence\nGoing further","lvl3":"Advanced queries\nQuery from interfaces","text":"To get started, you have to create a new project. This part will use Maven to illustrate the process but it is easily adaptable to Gradle or any Java based project.\nTo create a new Apache Maven project, you can use mvn archetype:generate but we recommend you to just create a folder and manually write a pom to avoid to inherit from a legacy setup.\nHere is a pom.xml template you can use to get started:\nEnsure to define your project metadata, note that this setup will be compatible with a multi-module project too,\nDefine uship version as a variable for easier upgrades (not required),\nWe use Yupiik Logging to get a more cloud friendly logging but this is not required at all, skip this dependency if not desired (if you prefer Log4j2 or so use JUL binding for example),\nWe want to write tests with JUnit 5 so we set it as dependency,\nJUnit 5.8.0-M1 got a pom bug so we force kotlin exclusion to workaround it,\nWe import the UShip bom to get dependencies versions right,\nWe force the encoding for resources to avoid surprises (OS dependent otherwise),\nWe force the compiler to use the Java version we want (note you can use any version >= 11),\nWe force surefire version to ensure we are JUnit 5 compatible,\nWe prevent surefire to trim the stack when an exception is thrown - it swallows the information you need to understand why it failed in general,\nWe force Yupiik logging manager (if you don’t use Yupiik Logging, skip it).\nµship does not use a parent pom to set it up automatically because: 1. it can quickly get outdated with transitive dependencies and project must be able to update any of the plugin/dependencies without a new µship release for flexibility, 2. you can use other plugins (junit-platform-maven-plugin instead of maven-surefire-plugin for example, spock, etc…), 3. it is saner to use a project related parent than a cross-project parent which is a bad practise and breaks several Maven features/integrations.\nAt that stage we have a good \"parent\" pom but to be able to code against it you should add the related dependencies. The simplest is to add this dependency:\nFrom here you can develop JSON-RPC endpoints.\nCreating a JSON-RPC endpoint is about marking a bean with the qualifier @JsonRpc and some method(s) with @JsonRpcMethod:\nDefines the class as containing JSON-RPC methods,\nSince the class will match a CDI bean, it can use any relevant scope. We strongly encourage you to use @ApplicationScoped if possible for performances and consistency but it is not required,\n@JsonRpcMethod defines a method usable over JSON-RPC transport (a servlet by default). The name attribute must be unique per deployment and we highly recommend you to set the documentation attribute,\nThe method can then define its return type and inputs as any JSON-B friendly types. Inputs can be marked with @JsonRpcParam to set their documentation.\nthe JSON-RPC implementation supports by position calls (parameters are passed in order) or names (JsonRpcParam#value). If not explicitly set, the name is taken from the parameter bytecode name. It is highly recommended to set -parameters to javac to get the same names than in the source code. Also take care that the order and names are then part of your contract.\nIf fully described - documentation methods being set in annotations, you can generate your endpoint documentation using jsonrpc-documentation module and in particular io.yupiik.uship.jsonrpc.doc.AsciidoctorJsonRpcDocumentationGenerator class.\nYou have to add this dependency to your pom.xml:\nThen add new exec build plugin instructions:\nWill generate a textual (Asciidoctor) documentation of your contract from the classes listed in the arguments,\nWill generate an OpenRPC (JSON) contract from the classes listed in the arguments.\nAs with any bulk friendly solution, you can optimize the JSON-RPC execution by implementing a kind of \"execution plan\" for the request. There are several cases it can be useful:\nYou receive a bulk request (array) which does N > 1 atomic findById and want to replace it by a single findByIds,\nYou have a custom bulk method,\nYou have a bulk request which can be optimized merging multiple requests (in this case the result of the first one can be dropped and only the last one will be used for ex.).\nLet’s take a concrete example:\nYou receive:\nIf you keep it this way you will do 2 queries (assume SQL ones for example). The idea is to replace them by an alternative execution which would do a single query.\nOne option, if you already have a method enabling that is to replace the method and then dispatch the results:\nThis can be done rewritting the request this way:\nThe issue then is to dispatch the result since instead of having 2 findById results you get a single one findByIds. The trick there is to pass a state in the HttpServletRequest as attribute and use it in handleRequest to be able to process the output:\nWe rewrite the request before its execution,\nWe process the response after its execution (take care to error cases).\nAs a guide, here is a skeleton for the request rewritter:\nAn alternative is to just override handleRequest to implement there the alternative execution paths:\nIf you want a more complete example of execution plan you can read execution plan example page.\nSimilarly to Asciidoctor documentation you can generate a collection of JSON-RPC requests using PostmanCollectionGenerator main. It takes an OpenRPC file (you can get it with openrpc method) and output a Postman collection file.\nSince UShip is mainly CDI based, it will be compatible with any kind of persistence Layer from SQL to NoSQL. However, for common simple cases, we ship a small JDBC mapper in our io.yupiik.uship:persistence module.\nIts scope is not to replace JPA but for simple cases to just provide a very light ORB. It only supports flat mapping - relationships must be managed by your which also means no magic or lazy query ;) - and transactions are managed through the DataSource. It works if the Connection is in autocommit mode or if you handle the commit through a transactional interceptor for example.\nThe entry point is the Database.of(configuration) factory then all operations are available on the database instance.\nHere some examples:\nMapping is a simple as:\nFor more advanced cases you can use query and batch methods from the Database instance.\nto setup a DataSource you can rely on org.apache.tomcat:tomcat-jdbc and TomcatDataSource extension which enables to bind a connection to a thread to reuse it in your code if needed.\nFor advanced queries you can use a virtual table (it is a plain table but the @Table annotation is ignored) which would be used as project based on query aliases:\nwith JoinModel being something like:\nOr you can also use Entity binder capacity:\n1.0.2 was broken, ensure to use >= 1.0.3 to get this feature.\nA light interface statement support is done through @Operation and @Statement annotations. The idea is to expose the Database capabilities through a statically typed API. Here is a sample:\nThe statements can be plain SQL with ? bindings or can use the available interpolations (but don’t mix ${parameters#xxx} with ? bindings, you must choose one type of binding per statement):\n${<alias>#table}: name of the table of the entity aliased by alias,\n${<alias>#fields}: all columns of the entity represented by the alias,\n${parameters#<name>}: will be replaced by a ? binding and the parameter named name (using bytecode name, ensure to compile with -parameter flag) will be used. It enables to not set the parameters in the same order than in the query because otherwise it is just bound blindly in order.\n${parameters#<name>#in}: will be replaced by as much ? than the size of the parameter name and surround the bindings by parenthesis prefixed by in ` keyword (ex: `in (?, ?) if name parameter is a list of 2 items). It is useful for in where clauses.\nAliases are defined through @Operation annotation on the interface and enables to have a shorter syntax in the statement. You can also use the fully qualified name of the entity instead of defining aliases but it is less readable.\nIt is possible to enrich the JSON-RPC protocol, in particular bulk request support, by reusing io.yupiik.uship.jsonrpc.core.impl.JsonRpcHandler class in your own endpoints. Typical examples are endpoint wrapping a set of request (sub methods), in a single transaction, endpoints propagating a state between method calls (like the second method will get the id generated in the first one), etc…","title":"Usage","url":"//yupiik.github.io/uship/development-stack.html"}]